-- Hoogle documentation, generated by Haddock
-- See Hoogle, http://www.haskell.org/hoogle/


-- | Heterogeneous, type-safe automatic backpropagation in Haskell
--   
--   See <a>README.md</a>
--   
--   At the moment, this project is in pre-alpha, and is published and put
--   up on Hackage with 100% documentation coverage as a call for comments
--   and thoughts. See <a>TODO</a> section in the README for more
--   information on what's missing and potential avenues for contribution.
@package backprop
@version 0.0.3.0


-- | Provides the <a>Op</a> type and combinators, which represent
--   differentiable functions/operations on values, and are used internally
--   by the library to perform back-propagation.
--   
--   Users of the library can ignore this module for the most part. Library
--   authors defining backpropagatable primitives for their functions are
--   recommend to simply use <a>op0</a>, <a>op1</a>, <a>op2</a>,
--   <a>op3</a>, which are re-exported in <a>Numeric.Backprop</a>. However,
--   authors who want more options in defining their primtive functions
--   might find some of these functions useful.
--   
--   Note that if your entire function is a single non-branching
--   composition of functions, <a>Op</a> and its utility functions alone
--   are sufficient to differentiate/backprop. However, this happens rarely
--   in practice.
module Numeric.Backprop.Op

-- | An <tt><a>Op</a> as a</tt> describes a differentiable function from
--   <tt>as</tt> to <tt>a</tt>.
--   
--   For example, a value of type
--   
--   <pre>
--   <a>Op</a> '[Int, Bool] Double
--   </pre>
--   
--   is a function from an <a>Int</a> and a <a>Bool</a>, returning a
--   <a>Double</a>. It can be differentiated to give a <i>gradient</i> of
--   an <a>Int</a> and a <a>Bool</a> if given a total derivative for the
--   <tt>Double</tt>. If we call <a>Bool</a> &lt;math&gt;, then,
--   mathematically, it is akin to a:
--   
--   &lt;math&gt;
--   
--   See <a>runOp</a>, <a>gradOp</a>, and <a>gradOpWith</a> for examples on
--   how to run it, and <a>Op</a> for instructions on creating it.
--   
--   It is simpler to not use this type constructor directly, and instead
--   use the <a>op2</a>, <a>op1</a>, <a>op2</a>, and <a>op3</a> helper
--   smart constructors And, if your function is a numeric function, they
--   can even be created automatically using <a>op1'</a>, <a>op2'</a>,
--   <a>op3'</a>, and <tt>opN</tt> with a little help from
--   <a>Numeric.AD</a> from the <i>ad</i> library.
newtype Op as a

-- | Construct an <a>Op</a> by giving a function creating the result, and
--   also a continuation on how to create the gradient, given the total
--   derivative of <tt>a</tt>.
--   
--   See the module documentation for <a>Numeric.Backprop.Op</a> for more
--   details on the function that this constructor and <a>Op</a> expect.
Op :: (Tuple as -> (a, a -> Tuple as)) -> Op as a

-- | Run the function that the <a>Op</a> encodes, returning a continuation
--   to compute the gradient, given the total derivative of <tt>a</tt>. See
--   documentation for <a>Numeric.Backprop.Op</a> for more information.
[runOpWith] :: Op as a -> Tuple as -> (a, a -> Tuple as)
data Prod k (f :: k -> *) (a :: [k]) :: forall k. () => (k -> *) -> [k] -> *
[Ø] :: Prod k f [] k
[:<] :: Prod k f (:) k a1 as

-- | A Prod of simple Haskell types.
type Tuple = Prod * I
newtype I a :: * -> *
I :: a -> I a
[getI] :: I a -> a

-- | Run the function that an <a>Op</a> encodes, to get the resulting
--   output and also its gradient with respect to the inputs.
--   
--   <pre>
--   &gt;&gt;&gt; gradOp' (op2 (*)) (3 ::&lt; 5 ::&lt; Ø)
--   (15, 5 ::&lt; 3 ::&lt; Ø)
--   </pre>
runOp :: Num a => Op as a -> Tuple as -> (a, Tuple as)

-- | Run the function that an <a>Op</a> encodes, to get the result.
--   
--   <pre>
--   &gt;&gt;&gt; runOp (op2 (*)) (3 ::&lt; 5 ::&lt; Ø)
--   15
--   </pre>
evalOp :: Op as a -> Tuple as -> a

-- | Run the function that an <a>Op</a> encodes, and get the gradient of
--   the output with respect to the inputs.
--   
--   <pre>
--   &gt;&gt;&gt; gradOp (op2 (*)) (3 ::&lt; 5 ::&lt; Ø)
--   5 ::&lt; 3 ::&lt; Ø
--   -- the gradient of x*y is (y, x)
--   </pre>
gradOp :: Num a => Op as a -> Tuple as -> Tuple as

-- | Get the gradient function that an <a>Op</a> encodes, with a third
--   argument expecting the total derivative of the result.
--   
--   See the module documentaiton for <a>Numeric.Backprop.Op</a> for more
--   information.
gradOpWith :: Op as a -> Tuple as -> a -> Tuple as

-- | Compose <a>Op</a>s together, like <a>sequence</a> for functions, or
--   <tt>liftAN</tt>.
--   
--   That is, given an <tt><a>Op</a> as b1</tt>, an <tt><a>Op</a> as
--   b2</tt>, and an <tt><a>Op</a> as b3</tt>, it can compose them with an
--   <tt><a>Op</a> '[b1,b2,b3] c</tt> to create an <tt><a>Op</a> as c</tt>.
composeOp :: (Every Num as, Known Length as) => Prod (Op as) bs -> Op bs c -> Op as c

-- | Convenient wrapper over <a>composeOp</a> for the case where the second
--   function only takes one input, so the two <a>Op</a>s can be directly
--   piped together, like for <a>.</a>.
composeOp1 :: (Every Num as, Known Length as) => Op as b -> Op '[b] c -> Op as c

-- | Convenient infix synonym for (flipped) <a>composeOp1</a>. Meant to be
--   used just like <a>.</a>:
--   
--   <pre>
--   <a>op1</a> negate            :: <a>Op</a> '[a]   a
--   <a>op2</a> (+)               :: Op '[a,a] a
--   
--   op1 negate <a>~.</a> op2 (+) :: Op '[a, a] a
--   </pre>
(~.) :: (Known Length as, Every Num as) => Op '[b] c -> Op as b -> Op as c
infixr 9 ~.

-- | A version of <a>composeOp</a> taking explicit <a>Length</a>,
--   indicating the number of inputs expected and their types.
--   
--   Requiring an explicit <a>Length</a> is mostly useful for rare
--   "extremely polymorphic" situations, where GHC can't infer the type and
--   length of the the expected input tuple. If you ever actually
--   explicitly write down <tt>as</tt> as a list of types, you should be
--   able to just use <a>composeOp</a>.
composeOp' :: forall as bs c. Every Num as => Length as -> Prod (Op as) bs -> Op bs c -> Op as c

-- | A version of <a>composeOp1</a> taking explicit <a>Length</a>,
--   indicating the number of inputs expected and their types.
--   
--   Requiring an explicit <a>Length</a> is mostly useful for rare
--   "extremely polymorphic" situations, where GHC can't infer the type and
--   length of the the expected input tuple. If you ever actually
--   explicitly write down <tt>as</tt> as a list of types, you should be
--   able to just use <a>composeOp1</a>.
composeOp1' :: Every Num as => Length as -> Op as b -> Op '[b] c -> Op as c

-- | Create an <a>Op</a> that takes no inputs and always returns the given
--   value.
--   
--   There is no gradient, of course (using <a>gradOp</a> will give you an
--   empty tuple), because there is no input to have a gradient of.
--   
--   <pre>
--   &gt;&gt;&gt; runOp (op0 10) Ø
--   (10, Ø)
--   </pre>
--   
--   For a constant <a>Op</a> that takes input and ignores it, see
--   <a>opConst</a> and <a>opConst'</a>.
op0 :: a -> Op '[] a

-- | An <a>Op</a> that ignores all of its inputs and returns a given
--   constant value.
--   
--   <pre>
--   &gt;&gt;&gt; gradOp' (opConst 10) (1 ::&lt; 2 ::&lt; 3 ::&lt; Ø)
--   (10, 0 ::&lt; 0 ::&lt; 0 ::&lt; Ø)
--   </pre>
opConst :: forall as a. (Every Num as, Known Length as) => a -> Op as a

-- | An <a>Op</a> that just returns whatever it receives. The identity
--   function.
--   
--   <pre>
--   <a>idOp</a> = <a>opIso</a> <a>id</a> <a>id</a>
--   </pre>
idOp :: Op '[a] a

-- | A version of <a>opConst</a> taking explicit <a>Length</a>, indicating
--   the number of inputs and their types.
--   
--   Requiring an explicit <a>Length</a> is mostly useful for rare
--   "extremely polymorphic" situations, where GHC can't infer the type and
--   length of the the expected input tuple. If you ever actually
--   explicitly write down <tt>as</tt> as a list of types, you should be
--   able to just use <a>opConst</a>.
opConst' :: forall as a. Every Num as => Length as -> a -> Op as a

-- | Create an <a>Op</a> of a function taking one input, by giving its
--   explicit derivative. The function should return a tuple containing the
--   result of the function, and also a function taking the derivative of
--   the result and return the derivative of the input.
--   
--   If we have
--   
--   &lt;math&gt;
--   
--   Then the derivative &lt;math&gt;, it would be:
--   
--   &lt;math&gt;
--   
--   If our <a>Op</a> represents &lt;math&gt;, then the second item in the
--   resulting tuple should be a function that takes &lt;math&gt; and
--   returns &lt;math&gt;.
--   
--   As an example, here is an <a>Op</a> that squares its input:
--   
--   <pre>
--   square :: Num a =&gt; <a>Op</a> '[a] a
--   square = <a>op1'</a> $ \x -&gt; (x*x, \d -&gt; 2 * d * x
--                         )
--   </pre>
--   
--   Remember that, generally, end users shouldn't directly construct
--   <a>Op</a>s; they should be provided by libraries or generated
--   automatically.
--   
--   For numeric functions, single-input <a>Op</a>s can be generated
--   automatically using <a>op1'</a>.
op1 :: (a -> (b, b -> a)) -> Op '[a] b

-- | Create an <a>Op</a> of a function taking two inputs, by giving its
--   explicit gradient. The function should return a tuple containing the
--   result of the function, and also a function taking the derivative of
--   the result and return the derivative of the input.
--   
--   If we have
--   
--   &lt;math&gt;
--   
--   Then the gradient &lt;math&gt; would be:
--   
--   &lt;math&gt;
--   
--   If our <a>Op</a> represents &lt;math&gt;, then the second item in the
--   resulting tuple should be a function that takes &lt;math&gt; and
--   returns &lt;math&gt;.
--   
--   As an example, here is an <a>Op</a> that multiplies its inputs:
--   
--   <pre>
--   mul :: Num a =&gt; <a>Op</a> '[a, a] a
--   mul = <a>op2'</a> $ \x y -&gt; (x*y, \d -&gt; (d*y, x*d)
--                        )
--   </pre>
--   
--   Remember that, generally, end users shouldn't directly construct
--   <a>Op</a>s; they should be provided by libraries or generated
--   automatically.
--   
--   For numeric functions, two-input <a>Op</a>s can be generated
--   automatically using <a>op2'</a>.
op2 :: (a -> b -> (c, c -> (a, b))) -> Op '[a, b] c

-- | Create an <a>Op</a> of a function taking three inputs, by giving its
--   explicit gradient. See documentation for <a>op2</a> for more details.
op3 :: (a -> b -> c -> (d, d -> (a, b, c))) -> Op '[a, b, c] d

-- | Automatically create an <a>Op</a> of a numerical function taking one
--   argument. Uses <a>diff</a>, and so can take any numerical function
--   polymorphic over the standard numeric types.
--   
--   <pre>
--   &gt;&gt;&gt; gradOp' (op1' (recip . negate)) (5 ::&lt; Ø)
--   (-0.2, 0.04 ::&lt; Ø)
--   </pre>
op1' :: Num a => (forall s. AD s (Forward a) -> AD s (Forward a)) -> Op '[a] a

-- | Automatically create an <a>Op</a> of a numerical function taking two
--   arguments. Uses <a>grad</a>, and so can take any numerical function
--   polymorphic over the standard numeric types.
--   
--   <pre>
--   &gt;&gt;&gt; gradOp' (op2' (\x y -&gt; x * sqrt y)) (3 ::&lt; 4 ::&lt; Ø)
--   (6.0, 2.0 ::&lt; 0.75 ::&lt; Ø)
--   </pre>
op2' :: Num a => (forall s. Reifies s Tape => Reverse s a -> Reverse s a -> Reverse s a) -> Op '[a, a] a

-- | Automatically create an <a>Op</a> of a numerical function taking three
--   arguments. Uses <a>grad</a>, and so can take any numerical function
--   polymorphic over the standard numeric types.
--   
--   <pre>
--   &gt;&gt;&gt; gradOp' (op3' (\x y z -&gt; (x * sqrt y)**z)) (3 ::&lt; 4 ::&lt; 2 ::&lt; Ø)
--   (36.0, 24.0 ::&lt; 9.0 ::&lt; 64.503 ::&lt; Ø)
--   </pre>
op3' :: Num a => (forall s. Reifies s Tape => Reverse s a -> Reverse s a -> Reverse s a -> Reverse s a) -> Op '[a, a, a] a

-- | Automatically create an <a>Op</a> of a numerical function taking
--   multiple arguments. Uses <a>grad</a>, and so can take any numerical
--   function polymorphic over the standard numeric types.
--   
--   <pre>
--   &gt;&gt;&gt; gradOp' (opN' (\(x :+ y :+ Ø) -&gt; x * sqrt y)) (3 ::&lt; 4 ::&lt; Ø)
--   (6.0, 2.0 ::&lt; 0.75 ::&lt; Ø)
--   </pre>
opN' :: (Num a, Known Nat n) => (forall s. Reifies s Tape => Vec n (Reverse s a) -> Reverse s a) -> Op (Replicate n a) a

-- | <tt><a>Replicate</a> n a</tt> is a list of <tt>a</tt>s repeated
--   <tt>n</tt> times.
--   
--   <pre>
--   &gt;&gt;&gt; :kind! Replicate N3 Int
--   '[Int, Int, Int]
--   
--   &gt;&gt;&gt; :kind! Replicate N5 Double
--   '[Double, Double, Double, Double, Double]
--   </pre>

-- | An <a>Op</a> that coerces an item into another item whose type has the
--   same runtime representation.
--   
--   <pre>
--   &gt;&gt;&gt; gradOp' opCoerce (Identity 5) :: (Int, Identity Int)
--   (5, Identity 1)
--   </pre>
--   
--   <pre>
--   <a>opCoerce</a> = <a>opIso</a> <tt>coerced</tt> <a>coerce</a>
--   </pre>
opCoerce :: Coercible a b => Op '[a] b

-- | An <a>Op</a> that takes <tt>as</tt> and returns exactly the input
--   tuple.
--   
--   <pre>
--   &gt;&gt;&gt; gradOp' opTup (1 ::&lt; 2 ::&lt; 3 ::&lt; Ø)
--   (1 ::&lt; 2 ::&lt; 3 ::&lt; Ø, 1 ::&lt; 1 ::&lt; 1 ::&lt; Ø)
--   </pre>
opTup :: Op as (Tuple as)

-- | An <a>Op</a> that runs the input value through an isomorphism.
--   
--   Warning: This is unsafe! It assumes that the isomorphisms themselves
--   have derivative 1, so will break for things like
--   <a>exponentiating</a>. Basically, don't use this for any "numeric"
--   isomorphisms.
opIso :: (a -> b) -> (b -> a) -> Op '[a] b
opLens :: Num a => Lens' a b -> Op '[a] b

-- | Construct a two element Prod. Since the precedence of (:&gt;) is
--   higher than (:&lt;), we can conveniently write lists like:
--   
--   <pre>
--   &gt;&gt;&gt; a :&lt; b :&gt; c
--   </pre>
--   
--   Which is identical to:
--   
--   <pre>
--   &gt;&gt;&gt; a :&lt; b :&lt; c :&lt; Ø
--   </pre>
infix 6 :>

-- | Build a singleton Prod.
only :: () => f a -> Prod k f (:) k a [] k
head' :: () => Prod k f (:<) k a as -> f a

-- | Cons onto a Tuple.
infixr 5 ::<

-- | Singleton Tuple.
only_ :: () => a -> Tuple (:) * a [] *

-- | Optimized version of <tt><a>op1</a> (<a>+</a>)</tt>.
(+.) :: Num a => Op '[a, a] a

-- | Optimized version of <tt><a>op1</a> (<a>-</a>)</tt>.
(-.) :: Num a => Op '[a, a] a

-- | Optimized version of <tt><a>op1</a> (<a>*</a>)</tt>.
(*.) :: Num a => Op '[a, a] a

-- | Optimized version of <tt><a>op1</a> <a>negate</a></tt>.
negateOp :: Num a => Op '[a] a

-- | Optimized version of <tt><a>op1</a> <a>abs</a></tt>.
absOp :: Num a => Op '[a] a

-- | Optimized version of <tt><a>op1</a> <a>signum</a></tt>.
signumOp :: Num a => Op '[a] a

-- | Optimized version of <tt><a>op1</a> (<a>/</a>)</tt>.
(/.) :: Fractional a => Op '[a, a] a

-- | Optimized version of <tt><a>op1</a> <a>recip</a></tt>.
recipOp :: Fractional a => Op '[a] a

-- | Optimized version of <tt><a>op1</a> <a>exp</a></tt>.
expOp :: Floating a => Op '[a] a

-- | Optimized version of <tt><a>op1</a> <a>log</a></tt>.
logOp :: Floating a => Op '[a] a

-- | Optimized version of <tt><a>op1</a> <a>sqrt</a></tt>.
sqrtOp :: Floating a => Op '[a] a

-- | Optimized version of <tt><a>op1</a> (<a>**</a>)</tt>.
(**.) :: Floating a => Op '[a, a] a

-- | Optimized version of <tt><a>op2</a> <a>logBase</a></tt>.
logBaseOp :: Floating a => Op '[a, a] a

-- | Optimized version of <tt><a>op1</a> <a>sin</a></tt>.
sinOp :: Floating a => Op '[a] a

-- | Optimized version of <tt><a>op1</a> <a>cos</a></tt>.
cosOp :: Floating a => Op '[a] a

-- | Optimized version of <tt><a>op1</a> <a>tan</a></tt>.
tanOp :: Floating a => Op '[a] a

-- | Optimized version of <tt><a>op1</a> <a>asin</a></tt>.
asinOp :: Floating a => Op '[a] a

-- | Optimized version of <tt><a>op1</a> <a>acos</a></tt>.
acosOp :: Floating a => Op '[a] a

-- | Optimized version of <tt><a>op1</a> <a>atan</a></tt>.
atanOp :: Floating a => Op '[a] a

-- | Optimized version of <tt><a>op1</a> <a>sinh</a></tt>.
sinhOp :: Floating a => Op '[a] a

-- | Optimized version of <tt><a>op1</a> <a>cosh</a></tt>.
coshOp :: Floating a => Op '[a] a

-- | Optimized version of <tt><a>op1</a> <a>tanh</a></tt>.
tanhOp :: Floating a => Op '[a] a

-- | Optimized version of <tt><a>op1</a> <a>asinh</a></tt>.
asinhOp :: Floating a => Op '[a] a

-- | Optimized version of <tt><a>op1</a> <a>acosh</a></tt>.
acoshOp :: Floating a => Op '[a] a

-- | Optimized version of <tt><a>op1</a> <a>atanh</a></tt>.
atanhOp :: Floating a => Op '[a] a
instance (Type.Class.Known.Known [*] (Data.Type.Length.Length *) as, Data.Type.Index.Every * GHC.Num.Num as, GHC.Num.Num a) => GHC.Num.Num (Numeric.Backprop.Op.Op as a)
instance (Type.Class.Known.Known [*] (Data.Type.Length.Length *) as, Data.Type.Index.Every * GHC.Real.Fractional as, Data.Type.Index.Every * GHC.Num.Num as, GHC.Real.Fractional a) => GHC.Real.Fractional (Numeric.Backprop.Op.Op as a)
instance (Type.Class.Known.Known [*] (Data.Type.Length.Length *) as, Data.Type.Index.Every * GHC.Float.Floating as, Data.Type.Index.Every * GHC.Real.Fractional as, Data.Type.Index.Every * GHC.Num.Num as, GHC.Float.Floating a) => GHC.Float.Floating (Numeric.Backprop.Op.Op as a)


-- | Provides the <tt>BP</tt> monad and the <a>BVar</a> type; after
--   manipulating <a>BVar</a>s (inputs to your function) to produce a
--   result, the library tracks internal data dependencies, which are used
--   to perform back-propagation (reverse-mode automatic differentiation)
--   to calculate the gradient of the output with respect to the inputs.
--   
--   Similar to automatic differentiation from the <i>ad</i> library and
--   <a>Numeric.AD.Mode.Reverse</a>, except for a few key differences:
--   
--   <ol>
--   <li>Most importantly, this library implements <i>heterogeneous</i>
--   back-propagation, so you can manipulate values of different types
--   (like different matrix and vector types, and product and sum types).
--   This is essential for things like back-propagation for neural
--   networks.</li>
--   <li>This module allows you to <i>explicitly</i> build your data
--   dependency graph if you wish, which allows the library to perform
--   optimizations and reduce extra allocation, which may or may not
--   provide advantages over <a>Numeric.AD.Mode.Reverse</a>'s
--   <a>unsafePerformIO</a>-based implicit graph building.</li>
--   </ol>
--   
--   See the <a>README</a> for more information and links to demonstrations
--   and tutorials. If you want to plunge right in, you can also look
--   directly at the main types, <tt>BP</tt>, <tt>BPOp</tt>, <a>BVar</a>,
--   <a>Op</a>, and the main functions, <a>backprop</a> and <tt>opVar</tt>.
--   
--   Note that every type involved has to be an instance of <a>Num</a>.
--   This is because gradients all need to be "summable" (which is
--   implemented using <a>sum</a> and <a>+</a>), and we also need to able
--   to generate gradients of '1' and '0'.
module Numeric.Backprop
data BVar s a
data W
constVar :: a -> BVar s a
liftOpN :: forall s as b. (Reifies s W, Num b, Every Num as) => Op as b -> Prod (BVar s) as -> BVar s b
liftOp1 :: forall s a b. (Reifies s W, Num a, Num b) => Op '[a] b -> BVar s a -> BVar s b
liftOp2 :: forall s a b c. (Reifies s W, Num a, Num b, Num c) => Op '[a, b] c -> BVar s a -> BVar s b -> BVar s c
liftOp3 :: forall s a b c d. (Reifies s W, Num a, Num b, Num c, Num d) => Op '[a, b, c] d -> BVar s a -> BVar s b -> BVar s c -> BVar s d
liftOp4 :: forall s a b c d e. (Reifies s W, Num a, Num b, Num c, Num d, Num e) => Op '[a, b, c, d] e -> BVar s a -> BVar s b -> BVar s c -> BVar s d -> BVar s e
lensVar :: forall a b s. (Reifies s W, Num a) => Lens' b a -> BVar s b -> BVar s a
(^^.) :: forall a b s. (Reifies s W, Num a) => BVar s b -> Lens' b a -> BVar s a
infixl 8 ^^.
uncurryVar :: (Num a, Num b) => (forall s. Reifies s W => BVar s a -> BVar s b -> BVar s c) -> (forall s. Reifies s W => BVar s (a, b) -> BVar s c)
backprop :: forall a b. (Num a, Num b) => (forall s. Reifies s W => BVar s a -> BVar s b) -> a -> (b, a)
evalBP :: forall a b. (Num a, Num b) => (forall s. Reifies s W => BVar s a -> BVar s b) -> a -> b
gradBP :: forall a b. (Num a, Num b) => (forall s. Reifies s W => BVar s a -> BVar s b) -> a -> a

-- | An <tt><a>Op</a> as a</tt> describes a differentiable function from
--   <tt>as</tt> to <tt>a</tt>.
--   
--   For example, a value of type
--   
--   <pre>
--   <a>Op</a> '[Int, Bool] Double
--   </pre>
--   
--   is a function from an <a>Int</a> and a <a>Bool</a>, returning a
--   <a>Double</a>. It can be differentiated to give a <i>gradient</i> of
--   an <a>Int</a> and a <a>Bool</a> if given a total derivative for the
--   <tt>Double</tt>. If we call <a>Bool</a> &lt;math&gt;, then,
--   mathematically, it is akin to a:
--   
--   &lt;math&gt;
--   
--   See <a>runOp</a>, <a>gradOp</a>, and <a>gradOpWith</a> for examples on
--   how to run it, and <a>Op</a> for instructions on creating it.
--   
--   It is simpler to not use this type constructor directly, and instead
--   use the <a>op2</a>, <a>op1</a>, <a>op2</a>, and <a>op3</a> helper
--   smart constructors And, if your function is a numeric function, they
--   can even be created automatically using <a>op1'</a>, <a>op2'</a>,
--   <a>op3'</a>, and <tt>opN</tt> with a little help from
--   <a>Numeric.AD</a> from the <i>ad</i> library.
newtype Op as a

-- | Construct an <a>Op</a> by giving a function creating the result, and
--   also a continuation on how to create the gradient, given the total
--   derivative of <tt>a</tt>.
--   
--   See the module documentation for <a>Numeric.Backprop.Op</a> for more
--   details on the function that this constructor and <a>Op</a> expect.
Op :: (Tuple as -> (a, a -> Tuple as)) -> Op as a

-- | Run the function that the <a>Op</a> encodes, returning a continuation
--   to compute the gradient, given the total derivative of <tt>a</tt>. See
--   documentation for <a>Numeric.Backprop.Op</a> for more information.
[runOpWith] :: Op as a -> Tuple as -> (a, a -> Tuple as)
data Prod k (f :: k -> *) (a :: [k]) :: forall k. () => (k -> *) -> [k] -> *
[Ø] :: Prod k f [] k
[:<] :: Prod k f (:) k a1 as

-- | A Prod of simple Haskell types.
type Tuple = Prod * I
newtype I a :: * -> *
I :: a -> I a
[getI] :: I a -> a

-- | Create an <a>Op</a> that takes no inputs and always returns the given
--   value.
--   
--   There is no gradient, of course (using <a>gradOp</a> will give you an
--   empty tuple), because there is no input to have a gradient of.
--   
--   <pre>
--   &gt;&gt;&gt; runOp (op0 10) Ø
--   (10, Ø)
--   </pre>
--   
--   For a constant <a>Op</a> that takes input and ignores it, see
--   <a>opConst</a> and <a>opConst'</a>.
op0 :: a -> Op '[] a

-- | An <a>Op</a> that ignores all of its inputs and returns a given
--   constant value.
--   
--   <pre>
--   &gt;&gt;&gt; gradOp' (opConst 10) (1 ::&lt; 2 ::&lt; 3 ::&lt; Ø)
--   (10, 0 ::&lt; 0 ::&lt; 0 ::&lt; Ø)
--   </pre>
opConst :: forall as a. (Every Num as, Known Length as) => a -> Op as a

-- | An <a>Op</a> that just returns whatever it receives. The identity
--   function.
--   
--   <pre>
--   <a>idOp</a> = <a>opIso</a> <a>id</a> <a>id</a>
--   </pre>
idOp :: Op '[a] a

-- | A version of <a>opConst</a> taking explicit <a>Length</a>, indicating
--   the number of inputs and their types.
--   
--   Requiring an explicit <a>Length</a> is mostly useful for rare
--   "extremely polymorphic" situations, where GHC can't infer the type and
--   length of the the expected input tuple. If you ever actually
--   explicitly write down <tt>as</tt> as a list of types, you should be
--   able to just use <a>opConst</a>.
opConst' :: forall as a. Every Num as => Length as -> a -> Op as a

-- | Create an <a>Op</a> of a function taking one input, by giving its
--   explicit derivative. The function should return a tuple containing the
--   result of the function, and also a function taking the derivative of
--   the result and return the derivative of the input.
--   
--   If we have
--   
--   &lt;math&gt;
--   
--   Then the derivative &lt;math&gt;, it would be:
--   
--   &lt;math&gt;
--   
--   If our <a>Op</a> represents &lt;math&gt;, then the second item in the
--   resulting tuple should be a function that takes &lt;math&gt; and
--   returns &lt;math&gt;.
--   
--   As an example, here is an <a>Op</a> that squares its input:
--   
--   <pre>
--   square :: Num a =&gt; <a>Op</a> '[a] a
--   square = <a>op1'</a> $ \x -&gt; (x*x, \d -&gt; 2 * d * x
--                         )
--   </pre>
--   
--   Remember that, generally, end users shouldn't directly construct
--   <a>Op</a>s; they should be provided by libraries or generated
--   automatically.
--   
--   For numeric functions, single-input <a>Op</a>s can be generated
--   automatically using <a>op1'</a>.
op1 :: (a -> (b, b -> a)) -> Op '[a] b

-- | Create an <a>Op</a> of a function taking two inputs, by giving its
--   explicit gradient. The function should return a tuple containing the
--   result of the function, and also a function taking the derivative of
--   the result and return the derivative of the input.
--   
--   If we have
--   
--   &lt;math&gt;
--   
--   Then the gradient &lt;math&gt; would be:
--   
--   &lt;math&gt;
--   
--   If our <a>Op</a> represents &lt;math&gt;, then the second item in the
--   resulting tuple should be a function that takes &lt;math&gt; and
--   returns &lt;math&gt;.
--   
--   As an example, here is an <a>Op</a> that multiplies its inputs:
--   
--   <pre>
--   mul :: Num a =&gt; <a>Op</a> '[a, a] a
--   mul = <a>op2'</a> $ \x y -&gt; (x*y, \d -&gt; (d*y, x*d)
--                        )
--   </pre>
--   
--   Remember that, generally, end users shouldn't directly construct
--   <a>Op</a>s; they should be provided by libraries or generated
--   automatically.
--   
--   For numeric functions, two-input <a>Op</a>s can be generated
--   automatically using <a>op2'</a>.
op2 :: (a -> b -> (c, c -> (a, b))) -> Op '[a, b] c

-- | Create an <a>Op</a> of a function taking three inputs, by giving its
--   explicit gradient. See documentation for <a>op2</a> for more details.
op3 :: (a -> b -> c -> (d, d -> (a, b, c))) -> Op '[a, b, c] d

-- | Automatically create an <a>Op</a> of a numerical function taking one
--   argument. Uses <a>diff</a>, and so can take any numerical function
--   polymorphic over the standard numeric types.
--   
--   <pre>
--   &gt;&gt;&gt; gradOp' (op1' (recip . negate)) (5 ::&lt; Ø)
--   (-0.2, 0.04 ::&lt; Ø)
--   </pre>
op1' :: Num a => (forall s. AD s (Forward a) -> AD s (Forward a)) -> Op '[a] a

-- | Automatically create an <a>Op</a> of a numerical function taking two
--   arguments. Uses <a>grad</a>, and so can take any numerical function
--   polymorphic over the standard numeric types.
--   
--   <pre>
--   &gt;&gt;&gt; gradOp' (op2' (\x y -&gt; x * sqrt y)) (3 ::&lt; 4 ::&lt; Ø)
--   (6.0, 2.0 ::&lt; 0.75 ::&lt; Ø)
--   </pre>
op2' :: Num a => (forall s. Reifies s Tape => Reverse s a -> Reverse s a -> Reverse s a) -> Op '[a, a] a

-- | Automatically create an <a>Op</a> of a numerical function taking three
--   arguments. Uses <a>grad</a>, and so can take any numerical function
--   polymorphic over the standard numeric types.
--   
--   <pre>
--   &gt;&gt;&gt; gradOp' (op3' (\x y z -&gt; (x * sqrt y)**z)) (3 ::&lt; 4 ::&lt; 2 ::&lt; Ø)
--   (36.0, 24.0 ::&lt; 9.0 ::&lt; 64.503 ::&lt; Ø)
--   </pre>
op3' :: Num a => (forall s. Reifies s Tape => Reverse s a -> Reverse s a -> Reverse s a -> Reverse s a) -> Op '[a, a, a] a

-- | Automatically create an <a>Op</a> of a numerical function taking
--   multiple arguments. Uses <a>grad</a>, and so can take any numerical
--   function polymorphic over the standard numeric types.
--   
--   <pre>
--   &gt;&gt;&gt; gradOp' (opN' (\(x :+ y :+ Ø) -&gt; x * sqrt y)) (3 ::&lt; 4 ::&lt; Ø)
--   (6.0, 2.0 ::&lt; 0.75 ::&lt; Ø)
--   </pre>
opN' :: (Num a, Known Nat n) => (forall s. Reifies s Tape => Vec n (Reverse s a) -> Reverse s a) -> Op (Replicate n a) a

-- | <tt><a>Replicate</a> n a</tt> is a list of <tt>a</tt>s repeated
--   <tt>n</tt> times.
--   
--   <pre>
--   &gt;&gt;&gt; :kind! Replicate N3 Int
--   '[Int, Int, Int]
--   
--   &gt;&gt;&gt; :kind! Replicate N5 Double
--   '[Double, Double, Double, Double, Double]
--   </pre>

-- | An <a>Op</a> that coerces an item into another item whose type has the
--   same runtime representation.
--   
--   <pre>
--   &gt;&gt;&gt; gradOp' opCoerce (Identity 5) :: (Int, Identity Int)
--   (5, Identity 1)
--   </pre>
--   
--   <pre>
--   <a>opCoerce</a> = <a>opIso</a> <tt>coerced</tt> <a>coerce</a>
--   </pre>
opCoerce :: Coercible a b => Op '[a] b

-- | An <a>Op</a> that takes <tt>as</tt> and returns exactly the input
--   tuple.
--   
--   <pre>
--   &gt;&gt;&gt; gradOp' opTup (1 ::&lt; 2 ::&lt; 3 ::&lt; Ø)
--   (1 ::&lt; 2 ::&lt; 3 ::&lt; Ø, 1 ::&lt; 1 ::&lt; 1 ::&lt; Ø)
--   </pre>
opTup :: Op as (Tuple as)

-- | An <a>Op</a> that runs the input value through an isomorphism.
--   
--   Warning: This is unsafe! It assumes that the isomorphisms themselves
--   have derivative 1, so will break for things like
--   <a>exponentiating</a>. Basically, don't use this for any "numeric"
--   isomorphisms.
opIso :: (a -> b) -> (b -> a) -> Op '[a] b
opLens :: Num a => Lens' a b -> Op '[a] b
